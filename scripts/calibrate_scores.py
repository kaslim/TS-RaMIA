#!/usr/bin/env python3
"""
T50e: æ¡ä»¶æ ¡å‡† - æ®‹å·®åŒ– + CDF æ ‡å‡†åŒ–
æ¶ˆé™¤æ··æ‚å˜é‡å¯¹è¯„åˆ†çš„å½±å“
"""

import argparse
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def residualize(df, score_cols, confound_cols, label_col='is_member'):
    """æ–¹æ³•1: æ®‹å·®åŒ– - åœ¨éæˆå‘˜ä¸Šæ‹Ÿåˆï¼Œå¾—åˆ°æ®‹å·®"""
    print("ğŸ“Š æ–¹æ³•1: æ®‹å·®åŒ–")
    
    # åªåœ¨éæˆå‘˜ä¸Šæ‹Ÿåˆ
    non_members = df[df[label_col] == 0].copy()
    
    # å‡†å¤‡æ··æ‚å˜é‡
    X_nm = non_members[confound_cols].values
    
    # å¯¹æ¯ä¸ªè¯„åˆ†åˆ—è¿›è¡Œæ®‹å·®åŒ–
    residual_cols = []
    for score_col in score_cols:
        print(f"  å¤„ç†: {score_col}")
        
        # æ‹Ÿåˆå›å½’æ¨¡å‹ï¼ˆç”¨æµ…å±‚æ¢¯åº¦æå‡æ ‘ï¼‰
        y_nm = non_members[score_col].values
        
        # å¤„ç† NaN
        valid_idx = ~(np.isnan(X_nm).any(axis=1) | np.isnan(y_nm))
        if valid_idx.sum() < 10:
            print(f"    âš ï¸ æœ‰æ•ˆæ ·æœ¬å¤ªå°‘ï¼Œè·³è¿‡")
            continue
        
        X_nm_valid = X_nm[valid_idx]
        y_nm_valid = y_nm[valid_idx]
        
        # æ ‡å‡†åŒ–æ··æ‚å˜é‡
        scaler = StandardScaler()
        X_nm_scaled = scaler.fit_transform(X_nm_valid)
        
        # æ‹Ÿåˆæ¨¡å‹
        model = GradientBoostingRegressor(
            n_estimators=50,
            max_depth=3,
            learning_rate=0.1,
            random_state=1337
        )
        model.fit(X_nm_scaled, y_nm_valid)
        
        # åœ¨å…¨éƒ¨æ•°æ®ä¸Šé¢„æµ‹
        X_all = df[confound_cols].values
        valid_all = ~np.isnan(X_all).any(axis=1)
        
        predictions = np.full(len(df), np.nan)
        if valid_all.sum() > 0:
            X_all_scaled = scaler.transform(X_all[valid_all])
            predictions[valid_all] = model.predict(X_all_scaled)
        
        # è®¡ç®—æ®‹å·®
        residuals = df[score_col].values - predictions
        
        # ä¿å­˜
        residual_col = f"{score_col}_resid"
        df[residual_col] = residuals
        residual_cols.append(residual_col)
        
        # è®¡ç®—ç›¸å…³æ€§ä¸‹é™
        orig_corr = np.abs([df[df[label_col]==0][score_col].corr(df[df[label_col]==0][conf]) 
                           for conf in confound_cols])
        resid_corr = np.abs([df[df[label_col]==0][residual_col].corr(df[df[label_col]==0][conf]) 
                            for conf in confound_cols])
        
        orig_corr_mean = np.nanmean(orig_corr)
        resid_corr_mean = np.nanmean(resid_corr)
        
        if orig_corr_mean > 0:
            reduction = (orig_corr_mean - resid_corr_mean) / orig_corr_mean * 100
            print(f"    åŸå§‹ç›¸å…³æ€§: {orig_corr_mean:.4f} â†’ æ®‹å·®ç›¸å…³æ€§: {resid_corr_mean:.4f} (â†“{reduction:.1f}%)")
    
    return df, residual_cols

def cdf_normalize(df, score_cols, confound_cols, label_col='is_member', n_bins=10):
    """æ–¹æ³•2: CDF æ ‡å‡†åŒ– - ç®€åŒ–ç‰ˆå…¨å±€ CDF"""
    print("\nğŸ“Š æ–¹æ³•2: CDF æ ‡å‡†åŒ– (å…¨å±€)")
    
    # åªåœ¨éæˆå‘˜ä¸Šè®¡ç®— CDF
    non_members = df[df[label_col] == 0].copy()
    
    cdf_cols = []
    for score_col in score_cols:
        print(f"  å¤„ç†: {score_col}")
        
        # ä½¿ç”¨å…¨å±€ CDFï¼ˆç®€åŒ–ç‰ˆï¼‰
        nm_scores = non_members[score_col].dropna().values
        
        if len(nm_scores) < 10:
            print(f"    âš ï¸ éæˆå‘˜æ ·æœ¬å¤ªå°‘ï¼Œè·³è¿‡")
            continue
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„åˆ†ä½æ•°ä½ç½®
        cdf_scores = []
        for score in df[score_col].values:
            if np.isnan(score):
                cdf_scores.append(np.nan)
            else:
                cdf = stats.percentileofscore(nm_scores, score, kind='rank') / 100.0
                cdf_scores.append(cdf)
        
        cdf_col = f"{score_col}_cdf"
        df[cdf_col] = cdf_scores
        cdf_cols.append(cdf_col)
        
        print(f"    CDF èŒƒå›´: [{np.nanmin(cdf_scores):.3f}, {np.nanmax(cdf_scores):.3f}]")
    
    return df, cdf_cols

def main():
    parser = argparse.ArgumentParser(description='T50e: æ¡ä»¶æ ¡å‡†')
    parser.add_argument('--csv_in', required=True, help='è¾“å…¥ CSV')
    parser.add_argument('--label_col', default='is_member', help='æ ‡ç­¾åˆ—')
    parser.add_argument('--confounds', nargs='+', required=True, help='æ··æ‚å˜é‡åˆ—')
    parser.add_argument('--methods', nargs='+', default=['residual', 'cdf'],
                       choices=['residual', 'cdf'], help='æ ¡å‡†æ–¹æ³•')
    parser.add_argument('--csv_out', required=True, help='è¾“å‡º CSV')
    
    args = parser.parse_args()
    
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("T50e: æ¡ä»¶æ ¡å‡†ï¼ˆæ®‹å·®åŒ– + CDF æ ‡å‡†åŒ–ï¼‰")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("")
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv(args.csv_in)
    print(f"ğŸ“Š åŠ è½½æ•°æ®: {len(df)} ä¸ªä½œå“")
    print(f"  æˆå‘˜: {(df[args.label_col]==1).sum()}")
    print(f"  éæˆå‘˜: {(df[args.label_col]==0).sum()}")
    print("")
    
    # æ£€æŸ¥æ··æ‚å˜é‡
    print(f"ğŸ“‹ æ··æ‚å˜é‡:")
    valid_confounds = []
    for conf in args.confounds:
        if conf in df.columns:
            print(f"  âœ“ {conf}")
            valid_confounds.append(conf)
        else:
            print(f"  âœ— {conf} (ç¼ºå¤±)")
    
    if not valid_confounds:
        print("\nâŒ æ²¡æœ‰æœ‰æ•ˆçš„æ··æ‚å˜é‡ï¼")
        return
    
    print("")
    
    # é€‰æ‹©è¦æ ¡å‡†çš„è¯„åˆ†åˆ—ï¼ˆTIS å’Œ PPL ç›¸å…³ï¼‰
    score_cols = [col for col in df.columns if any(x in col for x in ['tis_', 'ppl_']) 
                  and not any(x in col for x in ['_resid', '_cdf'])]
    
    # é™åˆ¶æ•°é‡ï¼Œé¿å…å¤ªå¤šåˆ—
    priority_scores = ['tis_win_p95_mean', 'tis_mean', 'tis_win_max_max', 
                      'ppl_fwd_mean', 'ppl_rev_mean']
    score_cols = [col for col in priority_scores if col in df.columns]
    
    print(f"ğŸ¯ å°†æ ¡å‡†çš„è¯„åˆ†åˆ— ({len(score_cols)} ä¸ª):")
    for col in score_cols:
        print(f"  â€¢ {col}")
    print("")
    
    # åº”ç”¨æ ¡å‡†æ–¹æ³•
    if 'residual' in args.methods:
        df, resid_cols = residualize(df, score_cols, valid_confounds, args.label_col)
    
    if 'cdf' in args.methods:
        df, cdf_cols = cdf_normalize(df, score_cols, valid_confounds, args.label_col)
    
    # ä¿å­˜ç»“æœ
    df.to_csv(args.csv_out, index=False)
    print(f"\nâœ… æ ¡å‡†ç»“æœå·²ä¿å­˜: {args.csv_out}")
    print(f"   æ–°å¢åˆ—æ•°: {len([c for c in df.columns if '_resid' in c or '_cdf' in c])}")
    
    print("")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("âœ… T50e å®Œæˆï¼")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

if __name__ == '__main__':
    main()

